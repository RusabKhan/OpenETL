# Use Python 3.12 slim image as base
FROM python:3.12-slim

# Set working directory in the container
WORKDIR /app

# Install required tools and OpenJDK 11
RUN apt-get update && apt-get install -y --no-install-recommends \
    wget \
    curl \
    tar \
    default-jre && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Install Spark (version 3.5.3) from the official Apache repo
RUN wget -q "https://downloads.apache.org/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz" && \
    tar -xvf spark-3.5.6-bin-hadoop3.tgz -C /opt && \
    rm spark-3.5.6-bin-hadoop3.tgz

# Set SPARK_HOME environment variable
ENV SPARK_HOME=/opt/spark-3.5.6-bin-hadoop3

# Add Spark binaries to the PATH
ENV PATH=$SPARK_HOME/bin:$PATH

# Copy backend application
COPY ./backend/requirements.txt /app/requirements.txt

# Install Python dependencies
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# COPY pyproject.toml /app/
COPY ./backend /app
COPY ./openetl_utils /app/openetl_utils
COPY ./connectors /app/connectors


# Expose the port for FastAPI
EXPOSE 5009

# Command to run the backend server
CMD ["gunicorn", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "main:app", "--bind", "0.0.0.0:5009"]