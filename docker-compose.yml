version: '3.9'

services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
      args:
        - DOCKER_BUILDKIT=1
    container_name: openetl-backend
    networks:
      - openetl-network
    ports:
      - "5009:5009"
    env_file:
      - .env
    restart: always
    volumes:
      - ~/.logs:/app/.logs

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
      args:
        NEXT_PUBLIC_API_URL: http://localhost:5009
    container_name: openetl-frontend
    networks:
      - openetl-network
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:5009
    restart: always

  spark-master:
    image: bitnami/spark:3.5.6
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_DRIVER_MEMORY=1g
      - SPARK_EXECUTOR_MEMORY=1g
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - SPARK_MASTER_LOG_DIR=/app/.logs
    ports:
      - "8080:8080"  # Spark Web UI
      - "7077:7077"  # Spark Master
    networks:
      - openetl-network
    restart: always
    volumes:
      - ~/.logs:/app/.logs

  spark-worker-1:
    image: bitnami/spark:3.5.6
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1g
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - SPARK_WORKER_LOG_DIR=/app/.logs
    networks:
      - openetl-network
    restart: always
    volumes:
      - ~/.logs:/app/.logs

  spark-worker-2:
    image: bitnami/spark:3.5.6
    container_name: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1g
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - SPARK_WORKER_LOG_DIR=/app/.logs
    networks:
      - openetl-network
    restart: always
    volumes:
      - ~/.logs:/app/.logs

  redis:
    image: redis
    container_name: redis
    networks:
      - openetl-network
    ports:
      - "6379:6379"
    restart: always

  scheduler:
    container_name: openetl-scheduler
    image: openetl-backend  # Use the backend image
    command: python3 openetl_utils/scheduler_utils.py
    env_file:
      - .env
    networks:
      - openetl-network
    restart: always
    volumes:
      - ~/.logs:/app/.logs

  celery_worker-1:
    container_name: openetl-celery-worker-1
    image: openetl-backend  # Use the backend image
    command: celery -A openetl_utils.celery_utils worker --loglevel=info --concurrency=4
    networks:
      - openetl-network
    env_file:
      - .env
    environment:
        - SPARK_DRIVER_HOST=openetl-pro-celery-worker-1
        - CELERYD_PREFETCH_MULTIPLIER=1
    depends_on:
      - redis
    restart: always
    volumes:
      - ~/.logs:/app/.logs


  db:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: openetl
      POSTGRES_PASSWORD: openetl123
      POSTGRES_DB: openetl_db
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks:
      - openetl-network
    restart: always

volumes:
  pgdata:

networks:
  openetl-network:
    driver: bridge
