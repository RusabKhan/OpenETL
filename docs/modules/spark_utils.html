

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>spark_utils module &mdash; OpenETL 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=8d563738"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="celery_utils module" href="celery_utils.html" />
    <link rel="prev" title="database_utils module" href="database_utils.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            OpenETL
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Utils</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="connector_utils.html">connector_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="local_connection_utils.html">local_connection_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_db_class.html">main_db_class module</a></li>
<li class="toctree-l1"><a class="reference internal" href="scheduler_utils.html">scheduler_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="cache.html">cache module</a></li>
<li class="toctree-l1"><a class="reference internal" href="database_utils.html">database_utils module</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">spark_utils module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#spark_utils.SparkConnection"><code class="docutils literal notranslate"><span class="pre">SparkConnection</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#spark_utils.SparkConnection.initializeSpark"><code class="docutils literal notranslate"><span class="pre">SparkConnection.initializeSpark()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#spark_utils.SparkConnection.read_via_spark"><code class="docutils literal notranslate"><span class="pre">SparkConnection.read_via_spark()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#spark_utils.SparkConnection.write_via_spark"><code class="docutils literal notranslate"><span class="pre">SparkConnection.write_via_spark()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#spark_utils.SparkConnection.__dispose__"><code class="docutils literal notranslate"><span class="pre">SparkConnection.__dispose__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#id0"><code class="docutils literal notranslate"><span class="pre">SparkConnection.initializeSpark()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#id1"><code class="docutils literal notranslate"><span class="pre">SparkConnection.read_via_spark()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2"><code class="docutils literal notranslate"><span class="pre">SparkConnection.write_via_spark()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="celery_utils.html">celery_utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="enums.html">enums module</a></li>
<li class="toctree-l1"><a class="reference internal" href="main_api_class.html">main_api_class module</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline_utils.html">pipeline_utils module</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tables/app.html">app module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tables/scheduler.html">scheduler module</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">OpenETL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">spark_utils module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/modules/spark_utils.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-spark_utils">
<span id="spark-utils-module"></span><h1>spark_utils module<a class="headerlink" href="#module-spark_utils" title="Link to this heading"></a></h1>
<p>This module contains utility functions and classes for working with Apache Spark.</p>
<p>Classes:
- SparkConnection: Represents a connection to a Spark cluster.</p>
<p>Functions:
- initializeSpark: Initializes a Spark connection and configures the Spark session based on the connection and configuration details.
- read_via_spark: Reads data using Spark based on the specified connection format and credentials.
- other_function_name(): Description of what this function does.
- another_function_name(): Description of what this function does.</p>
<dl class="py class">
<dt class="sig sig-object py" id="spark_utils.SparkConnection">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">SparkConnection</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">connection_string</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spark_configuration</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hadoop_configuration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#spark_utils.SparkConnection" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class representing a connection to a Spark cluster.</p>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">(str)</span></span></dt>
<dd><p>The connection string for the Spark cluster.</p>
<blockquote>
<div><p>spark_configuration (dict): Dictionary containing Spark configuration details.
hadoop_configuration (dict, optional): Dictionary containing Hadoop configuration details.
jar (None): Placeholder for the JAR file.</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="spark_utils.SparkConnection.initializeSpark">
<span class="sig-name descname"><span class="pre">initializeSpark</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#spark_utils.SparkConnection.initializeSpark" title="Link to this definition"></a></dt>
<dd><p>Initializes a Spark connection and configures the Spark session.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="spark_utils.SparkConnection.read_via_spark">
<span class="sig-name descname"><span class="pre">read_via_spark</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#spark_utils.SparkConnection.read_via_spark" title="Link to this definition"></a></dt>
<dd><p>Reads data using Spark based on the specified connection format and credentials.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="spark_utils.SparkConnection.write_via_spark">
<span class="sig-name descname"><span class="pre">write_via_spark</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conn_string</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">table</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">driver</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'append'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'jdbc'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#spark_utils.SparkConnection.write_via_spark" title="Link to this definition"></a></dt>
<dd><p>Writes data using Spark.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="spark_utils.SparkConnection.__dispose__">
<span class="sig-name descname"><span class="pre">__dispose__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#spark_utils.SparkConnection.__dispose__" title="Link to this definition"></a></dt>
<dd><p>Disposes the Spark session and engine.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">initializeSpark</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#id0" title="Link to this definition"></a></dt>
<dd><p>Initializes a Spark connection and configures the Spark session based on the connection and configuration details.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The initialized SparkSession object.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>pyspark.sql.SparkSession</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Exception</strong> – If an error occurs during Spark initialization.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id1">
<span class="sig-name descname"><span class="pre">read_via_spark</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spark_connection_details</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'jdbc'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id1" title="Link to this definition"></a></dt>
<dd><p>Reads data from a Spark DataFrame using limit/offset pagination, yielding batches of data until all rows are read.
Stops if all rows in a batch are null.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>spark_connection_details</strong> (<em>dict</em>) – The connection details.</p></li>
<li><p><strong>source_format</strong> (<em>str</em>) – The source format (e.g., “jdbc”).</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The number of rows per batch.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p><em>pyspark.sql.DataFrame</em> – A Spark DataFrame containing a batch of rows.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Exception</strong> – If an error occurs during the data reading process.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id2">
<span class="sig-name descname"><span class="pre">write_via_spark</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataframe</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conn_string</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">table</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">driver</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'append'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'jdbc'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id2" title="Link to this definition"></a></dt>
<dd><p>The write_via_spark method is used to write data using Spark based on the specified connection format and credentials.
It takes the DataFrame stored in the sparkDataframe attribute of the SparkConnection object and writes it to the target data destination.</p>
<p>The method requires a valid connection format and corresponding credentials to establish the connection for writing data.
It uses the write method of the DataFrame API, specifying the connection format, options, and save mode.</p>
<p>If any error occurs during the data writing process, an exception is raised.</p>
<p>This method is typically used after establishing a Spark connection, configuring the connection format and credentials, and preparing the data in the sparkDataframe attribute.</p>
<p>Please note that in the provided code snippet, the variables connection_type, connection_dict, and mode are not defined.
Make sure to replace them with the appropriate values based on your implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>Exception</strong> – If an error occurs during the data writing process.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="database_utils.html" class="btn btn-neutral float-left" title="database_utils module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="celery_utils.html" class="btn btn-neutral float-right" title="celery_utils module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, DataOmni Solutions.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>